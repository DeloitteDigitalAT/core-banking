{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker          \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 \n",
    "import psycopg2.extras \n",
    "import os\n",
    "from io import StringIO\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faker = Faker()\n",
    "final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    database=\"credit_risk\",\n",
    "    user=\"rootadmin\",\n",
    "    password=\"securepassword\",\n",
    "    host=\"creditrisk.cmcz6iv7alyg.eu-central-1.rds.amazonaws.com\",\n",
    "    port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data into Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker() \n",
    "def create_clientdata(x): \n",
    "  \n",
    "    # dictionary \n",
    "    client ={} \n",
    "    for i in range(0, x): \n",
    "        client[i]={} \n",
    "        client[i]['social_security_number']= fake.ssn() \n",
    "        client[i]['first_name']= faker.first_name() \n",
    "        client[i]['last_name']= faker.last_name() \n",
    "        client[i]['gender']= faker.random_element(elements=('M', 'F')) \n",
    "        client[i]['date_of_birth']= faker.date() \n",
    "        client[i]['created_date'] = datetime.datetime.now()\n",
    "        client[i]['citizenship'] = datetime.datetime.now()\n",
    "        client[i]['is_deleted'] = 'false'\n",
    "\n",
    "    \n",
    "    client_df = pd.DataFrame.from_dict(client)\n",
    "    client_f = client_df.T\n",
    "    client_f['social_security_number'] = client_f['social_security_number']\n",
    "    Client = client_f[['citizenship','first_name','last_name','social_security_number'\n",
    "                ,'gender','date_of_birth','created_date','is_deleted']]\n",
    "    return Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Client = create_clientdata(1000)\n",
    "tuples = [tuple(x) for x in Client.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Client.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('Client', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data into Contact details for each Client (1 per client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contactdata(x): \n",
    "  \n",
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    contacts ={} \n",
    "    for i in range(0, x): \n",
    "        contacts[i]={} \n",
    "        contacts[i]['phone_number']= fake.phone_number()\n",
    "        contacts[i]['id']= i +1\n",
    "        contacts[i]['created_date'] = datetime.datetime.now()\n",
    "        contacts[i]['is_deleted'] = 'false'\n",
    "        df = pd.DataFrame.from_dict(contacts)\n",
    "        contact = df.T\n",
    "    clients.insert(0, 'id', range(1, 1 + len(clients)))\n",
    "    contact_details = pd.merge(contact,clients, on=['id','id'])\n",
    "    contact_details['email_id'] = contact_details['first_name'].str.lower()+'.'+contact_details['last_name'].str.lower()+'@gmail.com'\n",
    "    Contacts = contact_details[['client_id','phone_number','email_id','created_date','is_deleted']]\n",
    "    return Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contact_Details = create_contactdata(1000)\n",
    "tuples = [tuple(x) for x in Contact_Details.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Contact_Details.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('contact_details', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data into family details for each Client (1 per client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_familydata(x): \n",
    "  \n",
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    family ={} \n",
    "    for i in range(0, x): \n",
    "        family[i]={} \n",
    "        family[i]['marital_status']= faker.random_element(elements=('Married', 'Single','Divorced','Engaged','In Civil Union'))\n",
    "        family[i]['residential_status']= faker.random_element(elements=('Alone', 'With Family','Shared Flat'))\n",
    "        family[i]['no_of_dependents']=  faker.pyint(min_value=0, max_value=3, step=1) \n",
    "        family[i]['id']= i +1\n",
    "        family[i]['created_date'] = datetime.datetime.now()\n",
    "        family[i]['is_deleted'] = 'false'\n",
    "        df = pd.DataFrame.from_dict(family)\n",
    "        fam = df.T\n",
    "    clients.insert(0, 'id', range(1, 1 + len(fam)))\n",
    "    families = pd.merge(fam,clients, on=['id','id'])\n",
    "    Family = families[['client_id','marital_status','residential_status','no_of_dependents','created_date','is_deleted']]\n",
    "    return Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Family_Details = create_familydata(1000)\n",
    "\n",
    "tuples = [tuple(x) for x in Family_Details.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Family_Details.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('family_details', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data for each credit application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_credit_application(x): \n",
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    credit ={} \n",
    "    for i in range(0, x): \n",
    "        credit[i]={} \n",
    "        credit[i]['status_date']= faker.date_between(start_date='-3y', end_date='today')\n",
    "        credit[i]['is_rejected_before']= faker.boolean()\n",
    "        credit[i]['status']= faker.random_element(elements=('In-progress', 'Rejected','New','Approved','On-hold'))\n",
    "        credit[i]['status_comments']= faker.sentence(nb_words=6, variable_nb_words=True, ext_word_list=None)\n",
    "        credit[i]['created_date'] = datetime.datetime.now()\n",
    "        credit[i]['is_deleted'] = 'false'\n",
    "        credit[i]['id']= i +1\n",
    "        df = pd.DataFrame.from_dict(credit)\n",
    "        cred = df.T\n",
    "    clients.insert(0, 'id', range(1, 1 + len(clients)))\n",
    "    credit_app = pd.merge(cred,clients, on=['id','id'])\n",
    "    CAS = credit_app[['client_id','status_date','is_rejected_before','status','status_comments','created_date','is_deleted']]\n",
    "    return CAS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit_Application = create_credit_application(1000)\n",
    "tuples = [tuple(x) for x in Credit_Application.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Credit_Application.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('credit_application_status', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data for address for each client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_address(x): \n",
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    address ={} \n",
    "    for i in range(0, x): \n",
    "        address[i]={} \n",
    "        address[i]['house_no']= faker.building_number()\n",
    "        address[i]['street_name']= faker.street_address()\n",
    "        address[i]['city']= faker.random_element(elements=('Vienna','Graz','Linz','Salzburg','Innsbruck','St. Polten')) \n",
    "        address[i]['postal_code']= faker.random_element(elements=('1010','1200','2020','2010','3010','4010')) \n",
    "        address[i]['created_date'] = datetime.datetime.now()\n",
    "        address[i]['is_deleted'] = 'false'\n",
    "        address[i]['id']= i +1\n",
    "        df = pd.DataFrame.from_dict(address)\n",
    "        adds = df.T\n",
    "    clients.insert(0, 'id', range(1, 1 + len(clients)))\n",
    "    address_details = pd.merge(adds,clients, on=['id','id'])\n",
    "    Address = address_details[['client_id','house_no','street_name','city','postal_code','created_date','is_deleted']]\n",
    "    return Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Address_details = create_address(1000)\n",
    "tuples = [tuple(x) for x in Address_details.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Address_details.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('address_details', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data for each client, 1 ID, 1 Meldezettle, 3 payslips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    Document_Columns = pd.DataFrame( columns = ['Name', 'Description','location','date','status']) \n",
    "    data = {\n",
    "        'name':['ID','Payslip1','Payslip2','Payslip3','Meldezettle'],\n",
    "        'description':['Identity Card','Payslip for month 1','Payslip for month 2','Payslip for month 3','Address proff'],\n",
    "        'location_url':['s3://core-banking-sample-data/Document samples/Id.jpg'\n",
    "              ,'s3://core-banking-sample-data/Document samples/Payslip.png'\n",
    "              ,'s3://core-banking-sample-data/Document samples/Payslip.png'\n",
    "              ,'s3://core-banking-sample-data/Document samples/Payslip.png'\n",
    "              ,'s3://core-banking-sample-data/Document samples/meldezettle.png'],\n",
    "        'created_date':[datetime.datetime.now(),datetime.datetime.now(),datetime.datetime.now(),datetime.datetime.now(),datetime.datetime.now()],\n",
    "        'is_deleted':['false','false','false','false','false'],\n",
    "        'category':['ID','Payslip','Payslip','Payslip','Meldezettle']\n",
    "       \n",
    "    }\n",
    "    Documents = pd.DataFrame(data, columns = ['name', 'description','location_url','created_date','is_deleted','category'])\n",
    "    Documents['id'] = 1\n",
    "    clients['id'] = 1\n",
    "    Documents = pd.merge(Documents, clients, on=['id'])\n",
    "    Documents = Documents[['client_id','name', 'description','location_url','created_date','is_deleted','category']]\n",
    "    #Documents    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [tuple(x) for x in Documents.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Documents.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('document_list', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data for each clients financial details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_financial_details(x): \n",
    "  \n",
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    credit ={} \n",
    "    for i in range(0, x): \n",
    "        credit[i]={} \n",
    "        credit[i]['employment_status']= faker.random_element(elements=('Unemployed','Employed-Fulltime','Employed-Parttime','Student','Selfemployed')) \n",
    "\n",
    "        credit[i]['id']= i +1\n",
    "        credit[i]['created_date'] = datetime.datetime.now()\n",
    "        credit[i]['is_deleted'] = 'false'\n",
    "        df = pd.DataFrame.from_dict(credit)\n",
    "        fin = df.T\n",
    "    \n",
    "    fin.loc[fin['employment_status'] == 'Unemployed', 'annual_income'] = 0\n",
    "    fin.loc[fin['employment_status'] == 'Student', 'annual_income'] = faker.pyint(min_value=10000, max_value=25000, step=1000) \n",
    "    fin.loc[fin['employment_status'] == 'Employed-Fulltime', 'annual_income'] = faker.pyint(min_value=30000, max_value=80000, step=1000) \n",
    "    fin.loc[fin['employment_status'] == 'Employed-Parttime', 'annual_income']  = faker.pyint(min_value=10000, max_value=40000, step=1000)\n",
    "    fin.loc[fin['employment_status'] == 'Selfemployed', 'annual_income']  = faker.pyint(min_value=10000, max_value=90000, step=1000)\n",
    "\n",
    "    fin.loc[(fin['employment_status'] == 'Unemployed')| (fin['employment_status'] == 'Student'), 'employed_years'] = 0\n",
    "    fin.loc[(fin['employment_status'] == 'Employed-Fulltime')| (fin['employment_status'] == 'Selfemployed'), 'employed_years'] = faker.pyint(min_value=1, max_value=20, step=1) \n",
    "    fin.loc[fin['employment_status'] == 'Employed-Parttime', 'employed_years']  = faker.pyint(min_value=1, max_value=5, step=1) \n",
    "\n",
    "    fin.loc[cred['employment_status'] == 'Employed-Fulltime', 'position'] = faker.random_element(elements=('Staff','Management','Owner','Selfemployed'))  \n",
    "    fin.loc[cred['employment_status'] == 'Selfemployed', 'position'] = 'Selfemployed' \n",
    "    fin.loc[(cred['employment_status'] == 'Employed-Parttime')|(fin['employment_status'] == 'Student'), 'position']  = faker.random_element(elements=('Parttime','Internship')) \n",
    "    fin.loc[cred['employment_status'] == 'Unemployed', 'position'] = 'N/A'\n",
    "\n",
    "    fin.loc[(cred['employment_status'] == 'Employed-Fulltime')|(fin['employment_status'] == 'Employed-Parttime'), 'company_employed'] = faker.random_element(elements=('Public','Private')) \n",
    "    fin.loc[(cred['employment_status'] != 'Employed-Fulltime')&(fin['employment_status'] != 'Employed-Parttime'), 'company_employed'] = 'N/A'\n",
    "    #credit[i]['company_employed']= faker.pyint(min_value=0, max_value=200, step=1)\n",
    "    \n",
    "    \n",
    "    clients.insert(0, 'id', range(1, 1 + len(clients)))\n",
    "    financial_details = pd.merge(fin,clients, on=['id','id'])\n",
    "    \n",
    "    #Credit = credit_info[['client_id','credit_amount','interest_rate','planned_emi','duration_in_months','created_date','is_deleted']]\n",
    "    #return Credit\n",
    "    financial_details = financial_details[['client_id','employment_status','annual_income','position','company_employed','employed_years','created_date','is_deleted']]\n",
    "\n",
    "    return financial_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_details = create_financial_details(1000)\n",
    "tuples = [tuple(x) for x in financial_details.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(financial_details.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('financial_information', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Data for each clients credit details for each loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_credit_details(x):\n",
    "    clients  = pd.read_sql(\"select client_id,first_name,last_name from client\", conn);\n",
    "    credit ={} \n",
    "    for i in range(0, x): \n",
    "        credit[i]={} \n",
    "        credit[i]['credit_amount']= faker.pyint(min_value=1, max_value=200, step=1)\n",
    "        credit[i]['id']= i +1\n",
    "        credit[i]['created_date'] = datetime.datetime.now()\n",
    "        credit[i]['is_deleted'] = 'false'\n",
    "        df = pd.DataFrame.from_dict(credit)\n",
    "        cred = df.T\n",
    "\n",
    "    cred['credit_amount'] = cred['credit_amount']*500\n",
    "    #Interest\n",
    "    cred.loc[cred[\"credit_amount\"] <=5000 , 'interest_rate'] = round(random.uniform(2, 3),2)\n",
    "    cred.loc[(cred[\"credit_amount\"] <=10000) & (cred[\"credit_amount\"] > 5000), 'interest_rate'] = round(random.uniform(1.5, 2),2)\n",
    "    cred.loc[(cred[\"credit_amount\"] <=50000) & (cred[\"credit_amount\"] > 10000)  , 'interest_rate'] = round(random.uniform(1, 1.5),2)\n",
    "    cred.loc[(cred[\"credit_amount\"] <=100000) & (cred[\"credit_amount\"] > 50000), 'interest_rate']  = round(random.uniform(0.5, 1),2)\n",
    "    \n",
    "     #Duration Months\n",
    "    cred.loc[cred[\"credit_amount\"] <=5000 , 'duration_in_months'] = 1\n",
    "    cred.loc[(cred[\"credit_amount\"] <=25000) & (cred[\"credit_amount\"] > 5000), 'duration_in_months'] = random.randrange(1, 3)\n",
    "    cred.loc[(cred[\"credit_amount\"] <=100000) & (cred[\"credit_amount\"] > 25000)  , 'duration_in_months'] = random.randrange(2, 8)\n",
    "\n",
    "    cred[\"i\"] =  ((cred[\"interest_rate\"]/100)*cred[\"duration_in_months\"])\n",
    "    cred[\"x\"] =  (cred[\"i\"]+1).pow(cred[\"duration_in_months\"].astype(int)*12)\n",
    "    \n",
    "    cred[\"planned_emi\"] =  ((cred[\"i\"]+1)*cred['credit_amount'])/(cred[\"duration_in_months\"]*12)\n",
    "    cred[\"duration_in_months\"] = cred[\"duration_in_months\"]*12\n",
    "    clients.insert(0, 'id', range(1, 1 + len(clients)))\n",
    "    Credit_details = pd.merge(cred,clients, on=['id','id'])\n",
    "    Credit_details = Credit_details[['client_id','credit_amount','interest_rate','planned_emi','duration_in_months','created_date','is_deleted']]\n",
    "\n",
    "    return Credit_details\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit_details = create_credit_details(1000)\n",
    "tuples = [tuple(x) for x in Credit_details.to_numpy()]\n",
    "    # Comma-separated dataframe columns\n",
    "cols = ','.join(list(Credit_details.columns))\n",
    "query  = \"INSERT INTO %s(%s) VALUES %%s\" % ('credit_information', cols)\n",
    "cursor = conn.cursor()\n",
    "psycopg2.extras.execute_values(cursor, query, tuples)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
